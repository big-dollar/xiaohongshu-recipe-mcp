import asyncio
import os
import re
import tempfile
import uuid
import sys
import subprocess
import threading
import io

# âœ… Fix: å¼ºåˆ¶ stdout/stderr ä½¿ç”¨ UTF-8 å¹¶å¼€å¯è¡Œç¼“å†²ï¼Œé˜²æ­¢ Windows ä¸‹ emoji å´©æºƒä»¥åŠè¾“å‡ºç©ºç™½
try:
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8', line_buffering=True)
    elif hasattr(sys.stdout, 'buffer'):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8', line_buffering=True)
    elif hasattr(sys.stderr, 'buffer'):
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)
except Exception:
    pass
from typing import List, Dict, Any, Optional

import httpx
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from mcp.server.models import InitializationOptions
import mcp.types as types
from mcp.server import NotificationOptions, Server
import mcp.server.stdio
from openai import AsyncOpenAI
from pydantic import BaseModel, Field
from publish_playwright import publish_with_playwright
import yt_dlp

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–æœåŠ¡å™¨
server = Server("xiaohongshu-recipe")

# é…ç½® OpenAI å®¢æˆ·ç«¯ (å…¼å®¹è‡ªå®šä¹‰ API)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
MODEL_NAME = os.getenv("MODEL_NAME", "gpt-3.5-turbo")

class RecipeData(BaseModel):
    title: str = Field(description="é£Ÿè°±æ ‡é¢˜")
    ingredients: List[str] = Field(description="é£Ÿæåˆ—è¡¨")
    steps: List[str] = Field(description="åˆ¶ä½œæ­¥éª¤")
    image_urls: List[str] = Field(description="å›¾ç‰‡é“¾æ¥åˆ—è¡¨")
    video_url: Optional[str] = Field(default=None, description="è§†é¢‘é“¾æ¥")

async def extract_recipe_from_url(url: str) -> RecipeData:
    """ä»ä»»æ„ç½‘é¡µæˆ–æœ¬åœ°HTMLæå–é£Ÿè°±å†…å®¹å’Œå›¾ç‰‡"""
    html_content = ""
    # åˆ¤æ–­æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶
    if os.path.isfile(url):
        try:
            with open(url, 'r', encoding='utf-8') as f:
                html_content = f.read()
        except Exception as e:
            print(f"è¯»å–æœ¬åœ°æ–‡ä»¶å¤±è´¥ ({e})")
            return RecipeData(title="", ingredients=[], steps=[], image_urls=[], video_url=None)
    else:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Sec-Ch-Ua": '"Chromium";v="122", "Not(A:Brand";v="24", "Google Chrome";v="122"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": '"Windows"',
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Upgrade-Insecure-Requests": "1"
        }
        
        # å°è¯•ä½¿ç”¨ httpx æŠ“å–
        try:
            async with httpx.AsyncClient(follow_redirects=True, http2=True) as client:
                response = await client.get(url, headers=headers)
                response.raise_for_status()
                html_content = response.text
        except Exception as e:
            print(f"HTTP è¯·æ±‚å¤±è´¥ ({e})ï¼Œå°è¯•ä½¿ç”¨ Playwright æŠ“å–...")
            # å¦‚æœ httpx å¤±è´¥ (æ¯”å¦‚é‡åˆ° Cloudflare æˆ– 403)ï¼Œå›é€€åˆ° playwright
            from playwright.async_api import async_playwright
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                context = await browser.new_context(user_agent=headers["User-Agent"])
                page = await context.new_page()
                await page.goto(url, wait_until="domcontentloaded", timeout=30000)
                html_content = await page.content()
                await browser.close()
            
    soup = BeautifulSoup(html_content, 'html.parser')

    # æå–æ ‡é¢˜ (å°è¯•å‡ ç§å¸¸è§çš„æ ‡é¢˜æ ‡ç­¾)
    title = ""
    if soup.title:
        title = soup.title.string.strip()
    if not title:
        h1 = soup.find('h1')
        if h1:
            title = h1.text.strip()
            
    # å°è¯•å¯»æ‰¾ä¸»è¦çš„é£Ÿè°±å†…å®¹åŒºåŸŸï¼Œä»¥é¿å…æŠ“å–åˆ°ä¾§è¾¹æ æˆ–æ¨èèœè°±çš„å›¾ç‰‡
    main_content = soup
    content_selectors = [
        '.card-recipe-detail',
        '.recipe-detail',
        'article',
        'main',
        '.recipe-content',
        '.post-content',
        '.entry-content',
        '#recipe-block',
        '[class*="recipe-content"]',
        '[class*="recipe-detail"]',
        '[class*="recipe"]',
        '[class*="content"]'
    ]
    
    for selector in content_selectors:
        found = soup.select_one(selector)
        if found:
            main_content = found
            break

    # æå–æ‰€æœ‰æ–‡æœ¬ä»¥ä¾› AI è§£æ
    # ç§»é™¤è„šæœ¬å’Œæ ·å¼
    for script in main_content(["script", "style", "nav", "footer", "header", "aside"]):
        script.extract()
    text = main_content.get_text(separator='\n', strip=True)
    
    # å°è¯•é€šè¿‡ BeautifulSoup å¯»æ‰¾è§†é¢‘é“¾æ¥ï¼Œå¦‚æœ yt-dlp å¤±è´¥
    video_url = None
    for video in main_content.find_all('video'):
         source = video.find('source')
         if source and source.get('src'):
             video_url = source.get('src')
             break
         elif video.get('src'):
             video_url = video.get('src')
             break
             
    if not video_url:
        # ç‰¹åˆ«å¤„ç†æŸäº›å¸¸è§ç½‘ç«™çš„è§†é¢‘æ ‡ç­¾æˆ– data å±æ€§
        for div in main_content.find_all(attrs={'data-video-url': True}):
            video_url = div.get('data-video-url')
            break
            
        # æœç´¢ iframe ä¸­çš„ youtube/vimeo é“¾æ¥
        if not video_url:
            for iframe in main_content.find_all('iframe'):
                src = iframe.get('src')
                if src and ('youtube.com/embed/' in src or 'player.vimeo.com/video/' in src):
                    video_url = src
                    # æŠŠ URL æ ¼å¼åŒ–ä¸ºæ ‡å‡†é“¾æ¥æ–¹ä¾¿ yt-dlp è§£æ
                    if 'youtube.com/embed/' in src:
                        video_id = src.split('youtube.com/embed/')[1]
                        if '?' in video_id:
                            video_id = video_id.split('?')[0]
                        video_url = f"https://www.youtube.com/watch?v={video_id}"
                    break
            
        # æœç´¢ script æ ‡ç­¾é‡Œçš„ .mp4 é“¾æ¥
        if not video_url:
            for script in main_content.find_all('script'):
                if script.string and '.mp4' in script.string:
                    import re
                    match = re.search(r'https?://[^\s\'"]+\.mp4[^\s\'"]*', script.string)
                    if match:
                        video_url = match.group(0)
                        break
    
    # æå–å›¾ç‰‡ URL
    images = []
    
    # ä¸€äº›ç”¨æ¥è¿‡æ»¤éæ­£æ–‡å›¾ç‰‡çš„ç‰¹å¾å…³é”®è¯
    exclude_classes = ['sidebar', 'widget', 'related', 'recommended', 'footer', 'nav', 'author', 'promo', 'category', 'categories', 'recipe-card', 'index-categories']
    
    # è·å–åŸå§‹çš„æ‰€æœ‰ img æ ‡ç­¾ï¼Œå› ä¸º main_content å¯èƒ½åˆ‡å¾—å¤ªç‹ äº†
    for img in main_content.find_all('img') + soup.find_all('img', class_='featured-image'):
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦åœ¨ä¸è¯¥åœ¨çš„åœ°æ–¹
        skip = False
        # å¦‚æœæ˜¯ç‰¹è‰²å¤§å›¾ï¼Œä¸è¦è·³è¿‡
        if 'featured-image' not in img.get('class', []):
            for parent in img.parents:
                if parent.name in ['aside', 'footer', 'nav']:
                    skip = True
                    break
                class_str = " ".join(parent.get('class', []))
                if any(exc in class_str.lower() for exc in exclude_classes):
                    skip = True
                    break
                
                # è¿‡æ»¤å¤–é“¾å›¾æˆ–è·³è½¬åˆ°å…¶ä»–é£Ÿè°±çš„å¡ç‰‡å¤§å›¾
                if parent.name == 'a':
                    href = parent.get('href', '')
                    # å¦‚æœè·³è½¬çš„ä¸æ˜¯å½“å‰ç½‘é¡µæœ¬èº«ï¼Œä¹Ÿä¸æ˜¯å¤§å›¾ç‰‡ï¼Œé‚£ä¹ˆå¤§æ¦‚ç‡æ˜¯å…¶ä»–é£Ÿè°±åˆ—è¡¨é¡¹æˆ–è€…å¹¿å‘Š
                    if href and url not in href and not href.lower().endswith(('.jpg', '.jpeg', '.png', '.webp', '.gif')) and not href.startswith('#'):
                        skip = True
                        break
        
        if skip:
            continue
            
        src = img.get('data-lazy-src') or img.get('src') or img.get('data-src') 
        if src and not src.startswith('data:'):
            # å¤„ç†ç›¸å¯¹è·¯å¾„
            if src.startswith('//'):
                src = 'https:' + src
            elif src.startswith('/'):
                from urllib.parse import urlparse
                parsed_url = urlparse(url)
                src = f"{parsed_url.scheme}://{parsed_url.netloc}{src}"
            
            # ç®€å•è¿‡æ»¤ï¼šå¿½ç•¥å¤ªå°çš„å›¾æ ‡æˆ–è€… base64
            if src.startswith('http') and not any(skip_word in src.lower() for skip_word in ['icon', 'logo', 'avatar', 'gif', 'svg', 'thumb', 'small', '150x150', '300x300', 'impression', 'pixel', 'dummy']):
                # å¦‚æœ URL ä¸­æœ‰æŸ¥è¯¢å‚æ•°æ§åˆ¶å¤§å°ï¼ˆæ¯”å¦‚ wp çš„å›¾åƒï¼‰ï¼Œå°½é‡ä¿ç•™åŸå›¾
                import re
                src = re.sub(r'-\d+x\d+\.(jpg|jpeg|png)$', r'.\1', src, flags=re.IGNORECASE)
                if src not in images:
                    images.append(src)
            elif src.startswith('file://') or os.path.isabs(src): # æ”¯æŒæœ¬åœ°å›¾ç‰‡
                if src not in images:
                    images.append(src)
    
    # ä½¿ç”¨ AI è§£æç½‘é¡µæ–‡æœ¬ï¼Œæå–ç»“æ„åŒ–çš„é£Ÿè°±æ•°æ®
    ai_client = AsyncOpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
    prompt = f"""
è¯·ä»ä»¥ä¸‹ç½‘é¡µæ–‡æœ¬ä¸­æå–é£Ÿè°±ä¿¡æ¯ï¼Œå¹¶ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚
å¦‚æœæ–‡æœ¬ä¸­ä¸åŒ…å«é£Ÿè°±ï¼Œè¯·å°½åŠ›æå–ä¸»è¦å†…å®¹ä½œä¸ºæ­¥éª¤ã€‚

ç½‘é¡µæ–‡æœ¬ï¼š
{text[:4000]} # æˆªæ–­ä»¥é¿å…è¶…å‡º token é™åˆ¶

è¯·è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- ingredients: å­—ç¬¦ä¸²æ•°ç»„ï¼ŒåŒ…å«æ‰€éœ€é£Ÿæçš„ä¸­æ–‡ç¿»è¯‘
- steps: å­—ç¬¦ä¸²æ•°ç»„ï¼ŒåŒ…å«åˆ¶ä½œæ­¥éª¤çš„ä¸­æ–‡ç¿»è¯‘
"""
    completion = await ai_client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é£Ÿè°±ä¿¡æ¯æå–åŠ©æ‰‹ï¼Œåªè¿”å›ç¬¦åˆæ ¼å¼çš„ JSONã€‚"},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"}
    )
    
    import json
    content = completion.choices[0].message.content
    if content:
       extracted_data = json.loads(content)
    else:
       extracted_data = {"ingredients": [], "steps": []}
    
    # å°è¯•é€šè¿‡ yt-dlp æå–è§†é¢‘ URL
    # YouTube / Vimeo ç­‰ä¸“ä¸šè§†é¢‘ç«™éœ€è¦ç‰¹æ®Šå¤„ç†
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'nocheckcertificate': True,
        'ignoreerrors': True,
        'no_color': True,
        # å…³é—­æµè§ˆå™¨ cookie çªƒå–ï¼Œå› ä¸ºå®ƒåœ¨ Windows ä¸Šå®¹æ˜“å¼•èµ·è®¨åŒä½†æ— å®³çš„çº¢å­—æŠ¥é”™
        # æˆ‘ä»¬ç”¨ä¸€ä¸ª dummy é€‰é¡¹è®©å®ƒä¸è¦æŠŠé”™è¯¯æ‰“åˆ° stderr æè„å±å¹•
        # âœ… Fix: lambda éœ€è¦æ¥å— (self, msg) ä¸¤ä¸ªå‚æ•°ï¼Œå¦åˆ™ yt-dlp è°ƒç”¨æ—¶æŠ¥ TypeError
        'logger': type('DummyLogger', (object,), {'debug': lambda self, msg: None, 'warning': lambda self, msg: None, 'error': lambda self, msg: None})(),
    }
    if not video_url:
        try:
             with yt_dlp.YoutubeDL(params=ydl_opts) as ydl: # type: ignore
                 info = ydl.extract_info(url, download=False)
                 if info:
                     video_url = info.get('url')
                     # å¦‚æœæ˜¯åµŒå¥—åœ¨æŸäº›é¡µé¢ä¸­çš„è§†é¢‘ï¼Œå¯èƒ½éœ€è¦å–ç¬¬ä¸€ä¸ªæ ¼å¼
                     formats = info.get('formats')
                     if video_url is None and formats:
                         for f in reversed(formats):
                             if f.get('url') and f.get('vcodec') != 'none':
                                 video_url = f.get('url')
                                 break
        except Exception as e:
             print(f"yt-dlp æå–è§†é¢‘ URL å¤±è´¥: {e}")

    return RecipeData(
        title=title,
        ingredients=extracted_data.get('ingredients', []),
        steps=extracted_data.get('steps', []),
        image_urls=list(set(images))[:9], # å°çº¢ä¹¦æœ€å¤š 9 å¼ å›¾
        video_url=video_url
    )

async def generate_xiaohongshu_post(recipe: RecipeData) -> Dict[str, str]:
    """æ ¹æ®é£Ÿè°±æ•°æ®ç”Ÿæˆå°çº¢ä¹¦é£æ ¼çš„ç¬”è®°"""
    ai_client = AsyncOpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
    
    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹æå–çš„é£Ÿè°±ä¿¡æ¯ï¼Œä¸ºæˆ‘ç”Ÿæˆä¸€ç¯‡ã€æœ‰æ•…äº‹æ€§ã€å®ç”¨æ€§ã€‘çš„çˆ†æ¬¾å°çº¢ä¹¦ç¾é£Ÿç¬”è®°ã€‚

ã€æ ¸å¿ƒè¦æ±‚ã€‘
1. æ ‡é¢˜ï¼ˆç»å¯¹ä¸èƒ½è¶…è¿‡18ä¸ªå­—ç¬¦ï¼ŒåŒ…å«emojiåœ¨å†…ï¼‰ï¼šå¿…é¡»æå…·å¸ç›æ•ˆæœï¼Œåˆ‡ä¸­ç—›ç‚¹æˆ–å¸¦æœ‰å¤¸å¼ å¸å¼•åŠ›ï¼ˆä¾‹å¦‚ï¼šç»äº†ï¼è¢«å…¨å®¶å¤¸ä¸Šå¤©çš„ç¥ä»™XXXï¼‰ã€‚
2. å¼€ç¯‡å¼•å…¥ï¼šç”¨ 1-2 å¥è¯è®²è¿°ä¸€ä¸ªå¼•èµ·å…±é¸£çš„å°æ•…äº‹æˆ–æ—¥å¸¸åœºæ™¯ï¼ˆä¾‹å¦‚ï¼šå‘¨æœ«ä¸çŸ¥é“åƒä»€ä¹ˆï¼Ÿ/ é—ºèœœå°äº†ä¸€å£ç›´æ¥æ‰¾æˆ‘è¦é…æ–¹ï¼‰ï¼Œè¿…é€ŸæŠ“ä½è¯»è€…çœ¼çƒã€‚
3. é£Ÿææ¸…å•ï¼šæ¸…æ™°åˆ—å‡ºæ‰€æœ‰å¿…éœ€é£Ÿæï¼Œå¯é€‚å½“æ ‡æ³¨ä»½é‡æˆ–æ›¿ä»£å“æç¤ºã€‚
4. åˆ¶ä½œæ­¥éª¤ï¼šåˆ†ç‚¹æ’°å†™ï¼Œè¯­è¨€å¿…é¡»é€šä¿—æ˜“æ‡‚ã€å…·æœ‰æå¼ºçš„å®æ“æ€§ã€‚æ¯ä¸€æ­¥çš„æ ¸å¿ƒåŠ¨ä½œè¦åŠ ç²—æˆ–ç”¨ emoji ç‚¹ç¼€ï¼Œè®©æ–°æ‰‹ä¹Ÿèƒ½ä¸€çœ‹å°±ä¼šã€‚
5. çˆ†æ¬¾è¯é¢˜ï¼ˆHashtagï¼‰ï¼šç»“å°¾å¤„å¿…é¡»æä¾› 5-8 ä¸ªè‡ªå¸¦é«˜æµé‡çš„ç²¾å‡†è¯é¢˜ï¼ˆä¾‹å¦‚ï¼š#å°çº¢ä¹¦çˆ†æ¬¾ç¾é£Ÿ #ç¥ä»™åƒæ³• #æ‡’äººé£Ÿè°± ç­‰ï¼‰ã€‚
6. æ’ç‰ˆä¸å­—æ•°ï¼šå…¨æ–‡æ€»å­—æ•°ä¸¥æ ¼æ§åˆ¶åœ¨ 800 å­—ä»¥å†…ã€‚å¤§é‡ä½¿ç”¨ emoji æå‡é˜…è¯»ä½“éªŒï¼Œæ®µè½ä¹‹é—´ç•™å‡ºç©ºè¡Œï¼Œä¿æŒæ’ç‰ˆå‘¼å¸æ„Ÿã€‚
7. æ ¼å¼è­¦å‘Šï¼šå°çº¢ä¹¦æ­£æ–‡ä¸æ”¯æŒ Markdown æ ¼å¼ï¼è¯·ç»å¯¹ä¸è¦ä½¿ç”¨ `**åŠ ç²—**`ã€`# æ ‡é¢˜` æˆ– `- åˆ—è¡¨` ç­‰ Markdown è¯­æ³•ï¼Œè¯·ä»…ä½¿ç”¨çº¯æ–‡æœ¬ã€æ¢è¡Œå’Œ Emoji è¿›è¡Œæ’ç‰ˆã€‚

é£Ÿè°±ä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{recipe.title}
é£Ÿæï¼š{', '.join(recipe.ingredients)}
æ­¥éª¤ï¼š
{chr(10).join(recipe.steps)}

è¯·ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- title: ç¬”è®°æ ‡é¢˜ (ç»å¯¹ä¸èƒ½è¶…è¿‡18ä¸ªå­—)
- content: ç¬”è®°æ­£æ–‡
"""
    completion = await ai_client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç†Ÿç»ƒæŒæ¡å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆé£æ ¼çš„ç¾é£Ÿåšä¸»ï¼Œåªè¿”å› JSONã€‚"},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"}
    )
    
    import json
    content = completion.choices[0].message.content
    if content:
        return json.loads(content)
    return {"title": recipe.title, "content": "\n".join(recipe.steps)}

async def download_image(url: str, save_dir: str, referer: str = "") -> Optional[str]:
    """ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼Œæ”¯æŒåŠ¨æ€ Referer ä»¥ç»•è¿‡ä¸åŒç½‘ç«™çš„é˜²ç›—é“¾ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒæœ¬åœ°å›¾ç‰‡è·¯å¾„"""
    try:
        if url.startswith('file://'):
            import shutil
            local_path = url[7:]
            if os.name == 'nt' and local_path.startswith('/'): # windows ä¸‹ file:///C:/ å˜æˆ /C:/
                local_path = local_path[1:]
            if os.path.exists(local_path):
                ext = local_path.split('.')[-1][:4] if '.' in local_path else 'jpg'
                file_path = os.path.join(save_dir, f"{uuid.uuid4().hex}.{ext}")
                shutil.copy2(local_path, file_path)
                return file_path
            return None
        elif os.path.isabs(url) and os.path.exists(url):
            import shutil
            ext = url.split('.')[-1][:4] if '.' in url else 'jpg'
            file_path = os.path.join(save_dir, f"{uuid.uuid4().hex}.{ext}")
            shutil.copy2(url, file_path)
            return file_path

        from urllib.parse import urlparse
        # åŠ¨æ€ç”Ÿæˆ Refererï¼šä½¿ç”¨æ¥æºé¡µé¢çš„åŸŸåï¼Œè‹¥æœªæŒ‡å®šåˆ™ä»å›¾ç‰‡ URL æ¨æ–­
        if not referer:
            parsed = urlparse(url)
            referer = f"{parsed.scheme}://{parsed.netloc}/"

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Sec-Ch-Ua": '"Chromium";v="122", "Not(A:Brand";v="24", "Google Chrome";v="122"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": '"Windows"',
            "Sec-Fetch-Dest": "image",
            "Sec-Fetch-Mode": "no-cors",
            "Sec-Fetch-Site": "cross-site",
            "Referer": referer
        }
        async with httpx.AsyncClient(follow_redirects=True, headers=headers) as client:
            response = await client.get(url)
            response.raise_for_status()
            
            # ä» URL è·å–åç¼€ï¼Œé»˜è®¤ jpg
            ext = url.split('.')[-1][:4] if '.' in url else 'jpg'
            # è¿‡æ»¤ç‰¹æ®Šå­—ç¬¦
            ext = re.sub(r'[^a-zA-Z0-9]', '', ext)
            if ext not in ['jpg', 'jpeg', 'png', 'webp']:
                 ext = 'jpg'
                 
            file_path = os.path.join(save_dir, f"{uuid.uuid4().hex}.{ext}")
            with open(file_path, 'wb') as f:
                f.write(response.content)
            return file_path
    except Exception as e:
        print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ {url}: {e}")
        return None



async def publish_to_xiaohongshu(title: str, content: str, image_urls: List[str], source_url: str = "", video_url: Optional[str] = None, save_draft: bool = False) -> str:
    """å°†ç¬”è®°å‘å¸ƒåˆ°å°çº¢ä¹¦"""
    from urllib.parse import urlparse

    # ä»åŸå§‹é¡µé¢ URL æå–åŸŸåï¼Œç”¨äºå›¾ç‰‡ä¸‹è½½æ—¶çš„ Refererï¼ˆç»•é˜²ç›—é“¾ï¼‰
    image_referer = ""
    if source_url:
        parsed = urlparse(source_url)
        image_referer = f"{parsed.scheme}://{parsed.netloc}/"

    # ä¸´æ—¶ç›®å½•ç”¨äºå­˜æ”¾ä¸‹è½½çš„å›¾ç‰‡å’Œè§†é¢‘ï¼Œä½¿ç”¨é•¿æ•ˆç›®å½•ä»¥ä¾¿ playwright æœ‰æ—¶é—´è¯»å–æ–‡ä»¶
    temp_dir = os.path.join(os.getcwd(), "temp_media")
    os.makedirs(temp_dir, exist_ok=True)
    
    try:
        # ä¼˜å…ˆå‘å¸ƒè§†é¢‘
        if video_url:
            print(f"æ­£åœ¨å‡†å¤‡ä¸‹è½½è§†é¢‘: {video_url}")
            video_path = os.path.join(temp_dir, f"{uuid.uuid4().hex}.mp4")
            
            cookie_path = os.path.join(os.getcwd(), 'cookies.txt')
            is_youtube = 'youtube.com' in video_url or 'youtu.be' in video_url
            
            # é’ˆå¯¹ YouTube çš„äº¤äº’å¼ Cookie æç¤º
            if is_youtube:
                while True:
                    if os.path.exists(cookie_path):
                        print(f"âœ… æ‰¾åˆ° cookies.txtï¼Œå¼€å§‹å°è¯•ä¸‹è½½...")
                        break
                    else:
                        print("\n" + "!"*50)
                        print("âš ï¸ æ£€æµ‹åˆ° YouTube è§†é¢‘ï¼Œä¸”å½“å‰ç›®å½•ç¼ºå°‘ cookies.txt æ–‡ä»¶ã€‚")
                        print("ğŸ‘‰ è¯·åœ¨æµè§ˆå™¨ä¸­å®‰è£… Get cookies.txt æ‰©å±•ï¼Œå¯¼å‡ºå¹¶ä¿å­˜åˆ°æœ¬é¡¹ç›®æ ¹ç›®å½•çš„ cookies.txt æ–‡ä»¶ä¸­ã€‚")
                        print("!"*50)
                        input("ä¿å­˜å®Œæˆåï¼Œè¯·æŒ‰ã€å›è½¦é”®ã€‘ç»§ç»­...")
            
            # å°è¯•ä¸‹è½½
            download_success = False
            while not download_success:
                ydl_opts = {
                    'outtmpl': video_path,
                    'quiet': False, # å…³é—­ quiet ä»¥ä¾¿ç”¨æˆ·èƒ½çœ‹åˆ° bot æ£€æµ‹é”™è¯¯
                    'no_warnings': False,
                    'nocheckcertificate': True,
                    'ignoreerrors': False, # æ”¹ä¸º False è®©å¤–éƒ¨æ•è·
                }
                
                if is_youtube:
                    # é’ˆå¯¹ YouTube æ·»åŠ  cookie å’Œ js_engine
                    if os.path.exists(cookie_path):
                        ydl_opts['cookiefile'] = cookie_path
                    ydl_opts['js_engine'] = 'nodejs' # ä½¿ç”¨ç”¨æˆ·æåˆ°çš„ nodejs ç»•è¿‡

                try:
                    import subprocess
                    if is_youtube and os.path.exists(cookie_path):
                        # å¦‚æœæ˜¯ YouTubeï¼Œç”±äº Python API å†…éƒ¨ç›´æ¥è°ƒç”¨æœ‰æ—¶æ— æ³•æ­£ç¡®æŒ‚è½½ node ç¯å¢ƒæ¥è§£å¯† JS æŒ‘æˆ˜
                        # è¿™é‡Œç›´æ¥é‡‡ç”¨ subprocess è°ƒç”¨å‘½ä»¤è¡Œçš„ yt-dlp æ¥å®ç°ä¸ç”¨æˆ·ç»ˆç«¯ä¸€è‡´çš„è¡Œä¸º
                        print("æ£€æµ‹åˆ° YouTube é“¾æ¥ï¼Œæ­£åœ¨é€šè¿‡ subprocess å”¤èµ· yt-dlp...")
                        cmd = [
                            'yt-dlp', 
                            '--cookies', cookie_path, 
                            '--js-runtimes', 'node', 
                            '--no-check-certificate',
                            '-o', video_path, 
                            video_url
                        ]
                        
                        loop = asyncio.get_running_loop()
                        def run_cmd():
                            # ä½¿ç”¨ errors='replace' æ¥é¿å… Windows å¹³å°ä¸‹çš„è§£ç æŠ¥é”™
                            process = subprocess.Popen(
                                cmd, 
                                stdout=subprocess.PIPE, 
                                stderr=subprocess.STDOUT, 
                                text=True, 
                                encoding='utf-8', 
                                errors='replace'
                            )
                            for line in process.stdout: # type: ignore
                                # å°† yt-dlp çš„ä¸‹è½½è¿›åº¦å®æ—¶æ‰“å°å‡ºæ¥
                                if '[download]' in line or '[youtube]' in line:
                                    # ä¸ºäº†ä¸åˆ·å±ï¼Œåªæ‰“å°éƒ¨åˆ†è¿›åº¦
                                    if 'ETA' in line:
                                        print(f"\\r{line.strip()}", end='', flush=True)
                                    else:
                                        print(f"\\n{line.strip()}", flush=True)
                            process.wait()
                            print("\\n")
                            # yt-dlp è¿”å›é 0 å³ä¸ºå¤±è´¥ï¼Œæˆ‘ä»¬å°†å…·ä½“çš„è¾“å‡ºä¿å­˜èµ·æ¥ç”¨äºå¤–éƒ¨æ•è·å…³é”®å­—
                            if process.returncode != 0:
                                return "error_bot_or_signin" # ç”¨ä¸€ä¸ªå›ºå®šå­—ç¬¦ä¸²æ›¿ä»£æ•°å­—ï¼Œè®©å¤–é¢æ›´å®¹æ˜“è¯†åˆ«å‡ºè¿™æ˜¯å¯èƒ½ç”±äº bot å¼•èµ·çš„
                            return process.returncode
                            
                        returncode = await loop.run_in_executor(None, run_cmd)
                        
                        if returncode == "error_bot_or_signin":
                            raise RuntimeError("yt-dlp æ‰§è¡Œå¤±è´¥ï¼Œæ£€æµ‹åˆ° bot æˆ– sign in ç›¸å…³é”™è¯¯")
                        elif returncode != 0:
                            raise RuntimeError(f"yt-dlp å­è¿›ç¨‹è¿”å›é”™è¯¯ç : {returncode}")
                    else:
                        loop = asyncio.get_running_loop()
                        await loop.run_in_executor(
                            None,
                            lambda: yt_dlp.YoutubeDL(params=ydl_opts).download([video_url]) # type: ignore
                        )
                    
                    if os.path.exists(video_path):
                        download_success = True
                    else:
                        raise RuntimeError("yt-dlp æ‰§è¡Œå®Œæˆä½†æœªç”Ÿæˆè§†é¢‘æ–‡ä»¶")
                        
                except Exception as e:
                    error_msg = str(e).lower()
                    print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
                    if is_youtube and ('bot' in error_msg or 'sign in' in error_msg):
                        print("\n" + "!"*50)
                        print("âš ï¸ ä¸‹è½½å¤±è´¥ï¼Œå¯èƒ½ cookies.txt å·²å¤±æ•ˆæˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚")
                        print("ğŸ‘‰ è¯·é‡æ–°å¯¼å‡ºæœ€æ–°çš„ cookies.txt æ–‡ä»¶è¦†ç›–åŸæ–‡ä»¶ã€‚")
                        print("å¦‚æœæƒ³æ”¾å¼ƒä¸‹è½½è¯¥è§†é¢‘è½¬è€Œå‘å¸ƒçº¯å›¾æ–‡ï¼Œè¯·ç›´æ¥å…³é—­æœ¬çª—å£ï¼Œæˆ–è€…è¾“å…¥ 'skip' å¹¶å›è½¦ã€‚")
                        print("!"*50)
                        user_input = input("æ›´æ–° cookies.txt åæŒ‰ã€å›è½¦é”®ã€‘é‡è¯•ï¼Œæˆ–è¾“å…¥ skip æ”¾å¼ƒè§†é¢‘ï¼š")
                        if user_input.strip().lower() == 'skip':
                            print("â­ï¸ ç”¨æˆ·é€‰æ‹©æ”¾å¼ƒè§†é¢‘ï¼Œé™çº§ä¸ºå›¾æ–‡æ¨¡å¼ã€‚")
                            break # è·³å‡º while å¾ªç¯
                    else:
                        # å…¶å®ƒé”™è¯¯ç›´æ¥è·³å‡ºè®©ä¸‹æ–¹ä»£ç æŠ¥é”™æˆ–é™çº§
                        break

            if download_success:
                # åŒæ—¶å¹¶å‘ä¸‹è½½æœ€å¤š 3 å¼ å›¾ç‰‡ä½œä¸ºè§†é¢‘å°é¢å›¾
                cover_image_paths: List[str] = []
                if image_urls:
                    print(f"è§†é¢‘æ¨¡å¼ï¼šå¹¶å‘ä¸‹è½½æœ€å¤š 3 å¼ å°é¢å›¾...")
                    cover_tasks = [
                        download_image(url, temp_dir, referer=image_referer)
                        for url in image_urls[:3]
                    ]
                    cover_results = await asyncio.gather(*cover_tasks, return_exceptions=True)
                    cover_image_paths = [
                        r for r in cover_results
                        if isinstance(r, str) and r
                    ]
                    print(f"å°é¢å›¾ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ {len(cover_image_paths)} / {min(len(image_urls), 3)} å¼ ")

                result = await publish_with_playwright(
                    title, content,
                    video_path=video_path,
                    cover_image_paths=cover_image_paths,
                    save_draft=save_draft
                )
                return result
            else:
                print("âš ï¸ è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºå›¾æ–‡æ¨¡å¼å‘å¸ƒ...")

        # æ²¡æœ‰è§†é¢‘åˆ™å¹¶å‘ä¸‹è½½å›¾ç‰‡ï¼ˆasyncio.gather å¹¶å‘ï¼Œæå‡é€Ÿåº¦ï¼‰
        print(f"å¼€å§‹å¹¶å‘ä¸‹è½½ {min(len(image_urls), 9)} å¼ å›¾ç‰‡...")
        download_tasks = [
            download_image(url, temp_dir, referer=image_referer)
            for url in image_urls[:9]  # é™åˆ¶æœ€å¤š 9 å¼ å›¾
        ]
        results = await asyncio.gather(*download_tasks, return_exceptions=True)
        local_image_paths = [
            r for r in results
            if isinstance(r, str) and r  # è¿‡æ»¤å¤±è´¥çš„ä»»åŠ¡ï¼ˆNone æˆ– Exceptionï¼‰
        ]
        print(f"å›¾ç‰‡ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ {len(local_image_paths)} / {min(len(image_urls), 9)} å¼ ")
        
        if not local_image_paths:
            # å…œåº•ï¼šå°è¯•ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„æµ‹è¯•å›¾ç‰‡
            print("æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°æµ‹è¯•å›¾ç‰‡...")
            test_img = os.path.join(os.path.dirname(os.path.abspath(__file__)), "test_lemon.jpg")
            if os.path.exists(test_img):
                local_image_paths.append(test_img)
            else:
                raise ValueError("æ²¡æœ‰æˆåŠŸä¸‹è½½åˆ°ä»»ä½•å›¾ç‰‡æˆ–è§†é¢‘ï¼Œæ— æ³•å‘å¸ƒç¬”è®°")
            
        # ä½¿ç”¨ Playwright å‘å¸ƒå›¾æ–‡
        result = await publish_with_playwright(title, content, image_paths=local_image_paths, save_draft=save_draft)
        return result
        
    finally:
        # å»¶è¿Ÿæ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œç¡®ä¿ playwright è¯»å–å®Œæˆ
        # å®é™…ä¸Šä¸ºäº†æ’æŸ¥é—®é¢˜ï¼Œæš‚æ—¶ä¸æ¸…ç†
        pass

@server.list_tools()
async def handle_list_tools() -> list[types.Tool]:
    """List available tools."""
    return [
        types.Tool(
            name="generate_and_publish_recipe",
            description="ä»ç»™å®šçš„é£Ÿè°±ç½‘é¡µURLæŠ“å–å†…å®¹ï¼Œä½¿ç”¨AIç”Ÿæˆå°çº¢ä¹¦ç¬”è®°é£æ ¼çš„æ–‡æ¡ˆï¼Œå¹¶è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨å‘å¸ƒåˆ°å°çº¢ä¹¦ï¼ˆé¦–æ¬¡éœ€æ‰«ç ï¼‰ã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {
                        "type": "string",
                        "description": "è¦æŠ“å–çš„é£Ÿè°±ç½‘é¡µURL"
                    }
                },
                "required": ["url"]
            }
        ),
        types.Tool(
            name="generate_and_save_draft_recipe",
            description="æŠ“å–é£Ÿè°±ç½‘é¡µå¹¶ç”Ÿæˆå°çº¢ä¹¦ç¬”è®°æ–‡æ¡ˆï¼Œä¹‹åæ‰“å¼€æµè§ˆå™¨å¡«å……å†…å®¹å¹¶ç‚¹å‡»'æš‚å­˜ç¦»å¼€'ï¼Œå­˜å…¥è‰ç¨¿ç®±ä¸ç«‹å³å‘å¸ƒã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {
                        "type": "string",
                        "description": "è¦æŠ“å–çš„é£Ÿè°±ç½‘é¡µURL"
                    }
                },
                "required": ["url"]
            }
        ),
        types.Tool(
            name="draft_recipe_note",
            description="ä»…ç”Ÿæˆå°çº¢ä¹¦ç¬”è®°è‰ç¨¿ï¼ˆæŠ“å–ç½‘é¡µ+ç”Ÿæˆæ–‡æ¡ˆ+è·å–å›¾ç‰‡é“¾æ¥ï¼‰ï¼Œä¸è¿›è¡Œå‘å¸ƒã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {
                        "type": "string",
                        "description": "è¦æŠ“å–çš„é£Ÿè°±ç½‘é¡µURL"
                    }
                },
                "required": ["url"]
            }
        )
    ]

def run_background_publish(url: str, save_draft: bool = False):
    """åœ¨ä¸€ä¸ªç‹¬ç«‹çš„è¿›ç¨‹ä¸­è¿è¡Œå‘å¸ƒä»»åŠ¡ï¼Œé¿å…é˜»å¡ MCP"""
    project_root = os.path.dirname(os.path.abspath(__file__))
    script = f"""
import asyncio
import sys
import os
import io

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥ server æ¨¡å—
sys.path.append(r"{project_root}")

from server import extract_recipe_from_url, generate_xiaohongshu_post, publish_to_xiaohongshu
from dotenv import load_dotenv

# è§£å†³ Windows ä¸‹ Emoji æ‰“å°å¯¼è‡´çš„ç¼–ç é—®é¢˜ï¼Œå¹¶è®¾ç½®ä¸ºè¡Œç¼“å†²ä»¥é˜²è¾“å‡ºå¡ä½
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8', line_buffering=True)
elif hasattr(sys.stdout, 'buffer'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)

load_dotenv()

async def main():
    try:
        # è·å–å‘½ä»¤è¡Œå‚æ•°ä¼ å…¥çš„ URL
        target_url = sys.argv[1] if len(sys.argv) > 1 else r"{url}"
        is_draft = sys.argv[2] == "True" if len(sys.argv) > 2 else {"True" if save_draft else "False"}
        print("\\n" + "="*40, flush=True)
        print(f"ğŸš€ æ•è·åˆ°æ–°ä»»åŠ¡ï¼", flush=True)
        print(f"ğŸ“ ç›®æ ‡ç½‘å€: {{target_url}}", flush=True)
        print("="*40 + "\\n", flush=True)
        
        print("ğŸ” æ­£åœ¨æŠ“å–å¹¶åˆ†æç½‘é¡µå†…å®¹...", flush=True)
        recipe_data = await extract_recipe_from_url(target_url)
        
        print("ğŸ“ æ­£åœ¨ä½¿ç”¨ AI ç”Ÿæˆçˆ†æ¬¾æ¨æ–‡...", flush=True)
        post_data = await generate_xiaohongshu_post(recipe_data)
        
        print(f"âœ¨ æ–‡æ¡ˆç”ŸæˆæˆåŠŸï¼æ ‡é¢˜: {{post_data.get('title', 'æ— æ ‡é¢˜')}}", flush=True)
        
        if recipe_data.video_url:
            print(f"ğŸ“¹ å‘ç°è§†é¢‘ï¼Œå‡†å¤‡ä¸‹è½½å¹¶å‘å¸ƒ...", flush=True)
        elif recipe_data.image_urls:
            print(f"ğŸ–¼ï¸ å‘ç° {{len(recipe_data.image_urls)}} å¼ å›¾ç‰‡ï¼Œå‡†å¤‡ä¸‹è½½å¹¶å‘å¸ƒ...", flush=True)
            
        print("ğŸŒ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨å‡†å¤‡å‘å¸ƒ...", flush=True)
        
        await publish_to_xiaohongshu(
            title=post_data['title'],
            content=post_data['content'],
            image_urls=recipe_data.image_urls,
            source_url=target_url,
            video_url=recipe_data.video_url,
            save_draft=is_draft
        )
        print("\\n================================", flush=True)
        print("âœ… å…¨éƒ¨æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼Œå·²æˆåŠŸå‘å¸ƒï¼", flush=True)
        print("================================", flush=True)
    except Exception as _e:
        print("\\n" + "!"*40, flush=True)
        print("âŒ åå°æ‰§è¡Œå‘ç”Ÿé”™è¯¯ä»¶", flush=True)
        print(str(_e), flush=True)
        print("!"*40 + "\\n", flush=True)
        import traceback
        traceback.print_exc()
        # è®°å½•é”™è¯¯åˆ°æœ¬åœ°æ–‡ä»¶ä¾¿äºæ’æŸ¥
        error_log_path = os.path.join(r"{project_root}", 'publish_error.log')
        with open(error_log_path, 'w', encoding='utf-8') as f:
            f.write(str(_e))
            f.write("\\n\\n")
            traceback.print_report(file=f)
    finally:
        print("\\nâ³ æœ¬æ§åˆ¶å°å°†åœ¨ 30 ç§’åè‡ªåŠ¨å…³é—­...", flush=True)
        await asyncio.sleep(30)

if __name__ == '__main__':
    asyncio.run(main())
"""
    # å†™å…¥ä¸´æ—¶è„šæœ¬å¹¶æ‰§è¡Œ
    import tempfile
    with tempfile.NamedTemporaryFile('w', delete=False, suffix='.py', encoding='utf-8') as f:
        f.write(script)
        temp_script_path = f.name
        
    # åœ¨åå°å¯åŠ¨è¿›ç¨‹ï¼Œé€šè¿‡å‘½ä»¤è¡Œä¼ å‚ URLï¼Œå¹¶æŒ‡å®šå·¥ä½œç›®å½•
    import subprocess
    env = os.environ.copy()
    env["PYTHONPATH"] = project_root
    env["PYTHONUNBUFFERED"] = "1"  # å¼ºåˆ¶å½»åº•å…³é—­ Python çš„è¾“å‡ºç¼“å†²
    
    if os.name == 'nt': # Windows
        # é’ˆå¯¹ Windows è·¯å¾„å¸¦ç©ºæ ¼çš„æƒ…å†µï¼Œæ‰‹åŠ¨æ„é€ å‘½ä»¤å­—ç¬¦ä¸²å¹¶ä½œä¸ºå•ä¸€å­—ç¬¦ä¸²ä¼ å…¥
        # é¿å… subprocess.Popen åˆ—è¡¨ä¼ å‚æ—¶è‡ªåŠ¨è½¬ä¹‰åŒå¼•å·
        command = f'cmd /k "chcp 65001 >nul & "{sys.executable}" "{temp_script_path}" "{url}" "{save_draft}""'
        subprocess.Popen(
            command, 
            creationflags=subprocess.CREATE_NEW_CONSOLE,
            cwd=project_root,
            env=env
        )
    else:
        subprocess.Popen(
            [sys.executable, temp_script_path, url, str(save_draft)], 
            start_new_session=True,
            cwd=project_root,
            env=env
        )

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict | None) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:
    """Handle tool execution requests."""
    if not arguments:
        raise ValueError("Missing arguments")

    if name in ["generate_and_publish_recipe", "generate_and_save_draft_recipe"]:
        url = arguments.get("url")
        if not url:
            raise ValueError("Missing url parameter")
            
        is_draft = (name == "generate_and_save_draft_recipe")
        try:
            # æ”¹ä¸ºå¼‚æ­¥è§¦å‘ï¼Œç«‹åˆ»è¿”å›ç»™å®¢æˆ·ç«¯
            run_background_publish(url, save_draft=is_draft)
            
            action_text = "å­˜è‰ç¨¿ï¼ˆæš‚å­˜ç¦»å¼€ï¼‰" if is_draft else "å‘å¸ƒ"
            return [types.TextContent(
                type="text",
                text=f"âœ… {action_text}ä»»åŠ¡å·²åœ¨åå°å¯åŠ¨ï¼\n\nè¯·æ³¨æ„ä½ çš„æ¡Œé¢ï¼Œç¨åä¼šè‡ªåŠ¨å¼¹å‡ºä¸€ä¸ªæµè§ˆå™¨çª—å£ã€‚\nå¦‚æœæ˜¯é¦–æ¬¡è¿è¡Œï¼Œè¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨ä¸­ç”¨æ‰‹æœºæ‰«ç ç™»å½•å°çº¢ä¹¦ã€‚"
            )]
        except Exception as e:
            return [types.TextContent(type="text", text=f"åå°ä»»åŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")]
            
    elif name == "draft_recipe_note":
         url = arguments.get("url")
         if not url:
             raise ValueError("Missing url parameter")
             
         try:
            # 1. æŠ“å–ç½‘é¡µå¹¶æå–ç»“æ„åŒ–æ•°æ®
            recipe_data = await extract_recipe_from_url(url)
            
            # 2. ç”Ÿæˆæ–‡æ¡ˆ
            post_data = await generate_xiaohongshu_post(recipe_data)
            
            result = f"""
## ç”Ÿæˆçš„ç¬”è®°è‰ç¨¿

### æ ‡é¢˜
{post_data['title']}

### æ­£æ–‡
{post_data['content']}

### æå–çš„è§†é¢‘é“¾æ¥
{recipe_data.video_url if recipe_data.video_url else 'æœªæ‰¾åˆ°è§†é¢‘'}

### æå–çš„å›¾ç‰‡é“¾æ¥ (å‰9å¼ )
{chr(10).join(recipe_data.image_urls[:9])}
"""
            return [types.TextContent(type="text", text=result)]
         except Exception as e:
            return [types.TextContent(type="text", text=f"æ‰§è¡Œè‰ç¨¿ç”Ÿæˆå¤±è´¥: {str(e)}")]

    raise ValueError(f"Unknown tool: {name}")

async def main():
    # Run the server using stdin/stdout streams
    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="xiaohongshu-recipe",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )

if __name__ == "__main__":
    asyncio.run(main())